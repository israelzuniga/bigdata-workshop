{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programando con Python Spark (PySpark)\n",
    "\n",
    "Recordando:\n",
    "- El driver program accesa al ambiente de Spark mediante un objeto SparkContext\n",
    "- El tipo de dato y concepto clave en Spark es el dataset llamados RDD\n",
    "- Cargamos datos en un RDD y hacemos operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â¡Nuestro primer programa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/apache-spark/spark/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master = \"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high-level APIs in Scala, Java, and Python, and an optimized engine that'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineasPython.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD\n",
    "\n",
    "**R**esilient **D**istributed **D**ateset (**RDD**)\n",
    "\n",
    "Recordando y agregando:\n",
    "- Contiene **Datos distribuidos** mediante **particiones** (de Workers)\n",
    "- Habilita **operaciones** para su **ejecuciÃ³n en paralelo**\n",
    "- Son **inmutables**\n",
    "- **En caso de pÃ©rdida, la computaciÃ³n ejecutada se re-ejecuta**\n",
    "\n",
    "\n",
    "Tres maneras de crear RDDs:\n",
    "\n",
    "- Mediante un dataset externo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuyendo una colecciÃ³n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformando un RDD existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones sobre RDDs\n",
    "\n",
    "#### Transformaciones\n",
    "\n",
    "Crean un nuevo RDD a partir de otro previo.\n",
    "\n",
    "P. ej.:\n",
    "*map()*\n",
    "\n",
    "\n",
    "#### Acciones\n",
    "\n",
    "Corre/ejecuta/computa un resultado basado en un RDD existente.\n",
    "\n",
    "P. ej.:\n",
    "*count()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProgramaciÃ³n Funcional con Python\n",
    "\n",
    "- Muchas transformaciones y algunas acciones esperan una funciÃ³n\n",
    "- En algunos casos, pueden ser funciones para operaciones mÃ¡s complejas\n",
    "- Para funciones simples, una expresiÃ³n lambda es conveniente:\n",
    "```python\n",
    ">>> lambda line: â€œPythonâ€ in line\n",
    "```\n",
    "\n",
    "\n",
    "### map()\n",
    "\n",
    "- Lee un elemento a la vez\n",
    "- Toma un valor, crea un nuevo valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[23] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: x * 2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter()\n",
    "\n",
    "- Lee un elemento a la vez\n",
    "- Evalua cada elemento\n",
    "- Regresa los elementos que pasan el filtro  (filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[26] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x: x % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x: x % 2 == 0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatMap()\n",
    "\n",
    "Produce multiples elementos por cada elemento de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[31] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: [x, x * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[34] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x: [x, x * 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations are lazy!\n",
    "## Featuring: Lazy evaluation!! ðŸ”¥ðŸ™ˆ\n",
    "\n",
    "[Haskell Lazy Evaluation](https://wiki.haskell.org/Lazy_evaluation):\n",
    "\n",
    ">Lazy evaluation is a method to evaluate a Haskell program. It means that expressions are not evaluated when they are bound to variables, but their evaluation is deferred until their results are needed by other computations. In consequence, arguments are not evaluated before they are passed to a function, but only when their values are actually used. \n",
    "\n",
    "[The Incomplete Guide to Lazy Evaluation (in Haskell)](https://hackhands.com/guide-lazy-evaluation-haskell/):\n",
    "\n",
    "> Originally, I wanted to write a complete guide to lazy evaluation, but then.\n",
    "\n",
    ">Lazy evaluation is the most widely used method for executing Haskell program code on a computer. It determines the time and memory usage of Haskell programs, and it allows new and powerful ways to write modular code. To make full use of purely functional programming, a good understanding of lazy evaluation is very helpful.\n",
    "\n",
    "\n",
    "Un RDD solo es ejecutado cuando las acciones corren sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)\n",
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[39] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineasPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high-level APIs in Scala, Java, and Python, and an optimized engine that'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineasPython.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar la evaluaciÃ³n floja, Spark puede contener en memoria RDD que se procesa unicamente cuando se le requiere. Sin la necesidad de cargar a memoria todas las lineas conteniendo \"Python\".\n",
    "\n",
    "\n",
    "ðŸ’»ðŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acciones\n",
    "\n",
    "- Las acciones causan transformaciones para ser almacenadas en RDDs nuevos\n",
    "- TambiÃ©n regresan resultados a ambas partes: el *driver* o un almacenamiento externo\n",
    "- Los RDDs son re-calculados por cada acciÃ³n que se les ejecuta\n",
    "- Pueden ser almacenados para un uso posterior: `rdd.persist()`\n",
    "\n",
    "### count()\n",
    "\n",
    "Obtiene las instancias en el RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[42] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect()\n",
    "- `collect()` recupera el RDD completo ðŸš’\n",
    "- Ãštil para inspeccionar datasets pequeÃ±os de manera local y para unit-testing\n",
    "- **LOS RESULTADOS DEBEN CABER EN LA MEMORIA DEL EQUIPO LOCAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[44] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take(), takeSample(), first(), top(), takeOrdered() \n",
    "\n",
    "- ```take(n)``` regresa los primeros *n* elementos de un RDD\n",
    "- ```take(n)``` puede obtener resultados sezgados. Su uso es adecuado solo para pruebas o debugging\n",
    "- ```takeSample()``` como el nombre lo indica, es el mÃ¡s adecuado para tomar una muesta del dataset\n",
    "- ```first(n)``` al igual que ```take(n)```, obtiene los primeros *n* elementos de un RDD\n",
    "- ```top(), takeOrdered()``` como mÃ©todos mÃ¡s formales para obtener elementos ordenados de un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([5, 1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 1]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(4, lambda n: -n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce()\n",
    "Toma dos elementos del mismo tipo y regresa un nuevo elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduce(lambda x, y:  x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia\n",
    "- Spark re-calcula los RDDs cada vez que se llama a una acciÃ³n:\n",
    "    - Esto puede ser caro y tambiÃ©n causar un trÃ¡fico innecesario desde el disco (lectura)\n",
    "- Podemos evitar esto almacenando datos en cachÃ© con ```persist()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Causa a Spark el recargar la variable \"lineas\" desde el disco ðŸ™Š\n",
    "lineasPython.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md MapPartitionsRDD[57] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.persist() # Ahora, este RDD se mantiene en RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark no volverÃ¡ a hacer el cÃ³mputo para \"lineas\" cada vez que es usado\n",
    "lineasPython.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo un Pipeline de operaciones para RDDs\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    ">>> lineas = sc.textFile(\"README.md\")\n",
    ">>> lineas.map(...).filter(...).count(...)\n",
    "\n",
    "\n",
    "\n",
    ">>> lineas = sc.textFile(\"README.md\")\n",
    ">>> (lineas\n",
    "     .map(...)\n",
    "     .filter(...)\n",
    "     .count(...))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.filter(lambda line :  \"Python\" in line).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
