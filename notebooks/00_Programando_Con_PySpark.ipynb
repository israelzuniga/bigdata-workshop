{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programando con Python Spark (PySpark)\n",
    "\n",
    "Recordando:\n",
    "- El driver program accesa al ambiente de Spark mediante un objeto SparkContext\n",
    "- El tipo de dato y concepto clave en Spark es el dataset llamados RDD\n",
    "- Cargamos datos en un RDD y hacemos operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬°Nuestro primer programa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/apache-spark/spark/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master = \"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high-level APIs in Scala, Java, and Python, and an optimized engine that'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineasPython.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD\n",
    "\n",
    "**R**esilient **D**istributed **D**ateset (**RDD**)\n",
    "\n",
    "Recordando y agregando:\n",
    "- Contiene **Datos distribuidos** mediante **particiones** (de Workers)\n",
    "- Habilita **operaciones** para su **ejecuci√≥n en paralelo**\n",
    "- Son **inmutables**\n",
    "- **En caso de p√©rdida, la computaci√≥n ejecutada se re-ejecuta**\n",
    "\n",
    "\n",
    "Tres maneras de crear RDDs:\n",
    "\n",
    "- Mediante un dataset externo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuyendo una colecci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformando un RDD existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones sobre RDDs\n",
    "\n",
    "#### Transformaciones\n",
    "\n",
    "Crean un nuevo RDD a partir de otro previo.\n",
    "\n",
    "P. ej.:\n",
    "*map()*\n",
    "\n",
    "\n",
    "#### Acciones\n",
    "\n",
    "Corre/ejecuta/computa un resultado basado en un RDD existente.\n",
    "\n",
    "P. ej.:\n",
    "*count()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programaci√≥n Funcional con Python\n",
    "\n",
    "- Muchas transformaciones y algunas acciones esperan una funci√≥n\n",
    "- En algunos casos, pueden ser funciones para operaciones m√°s complejas\n",
    "- Para funciones simples, una expresi√≥n lambda es conveniente:\n",
    "```python\n",
    ">>> lambda line: ‚ÄúPython‚Äù in line\n",
    "```\n",
    "\n",
    "\n",
    "### map()\n",
    "\n",
    "- Lee un elemento a la vez\n",
    "- Toma un valor, crea un nuevo valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[23] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: x * 2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter()\n",
    "\n",
    "- Lee un elemento a la vez\n",
    "- Evalua cada elemento\n",
    "- Regresa los elementos que pasan el filtro  (filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[26] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x: x % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x: x % 2 == 0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatMap()\n",
    "\n",
    "Produce multiples elementos por cada elemento de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[31] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(lambda x: [x, x * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[34] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.flatMap(lambda x: [x, x * 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations are lazy!\n",
    "## Featuring: Lazy evaluation!! üî•üôà\n",
    "\n",
    "[Haskell Lazy Evaluation](https://wiki.haskell.org/Lazy_evaluation):\n",
    "\n",
    ">Lazy evaluation is a method to evaluate a Haskell program. It means that expressions are not evaluated when they are bound to variables, but their evaluation is deferred until their results are needed by other computations. In consequence, arguments are not evaluated before they are passed to a function, but only when their values are actually used. \n",
    "\n",
    "[The Incomplete Guide to Lazy Evaluation (in Haskell)](https://hackhands.com/guide-lazy-evaluation-haskell/):\n",
    "\n",
    "> Originally, I wanted to write a complete guide to lazy evaluation, but then.\n",
    "\n",
    ">Lazy evaluation is the most widely used method for executing Haskell program code on a computer. It determines the time and memory usage of Haskell programs, and it allows new and powerful ways to write modular code. To make full use of purely functional programming, a good understanding of lazy evaluation is very helpful.\n",
    "\n",
    "\n",
    "Un RDD solo es ejecutado cuando las acciones corren sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)\n",
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[39] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineasPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high-level APIs in Scala, Java, and Python, and an optimized engine that'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineasPython.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar la evaluaci√≥n floja, Spark puede contener en memoria RDD que se procesa unicamente cuando se le requiere. Sin la necesidad de cargar a memoria todas las lineas conteniendo \"Python\".\n",
    "\n",
    "\n",
    "üíªüêç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acciones\n",
    "\n",
    "- Las acciones causan transformaciones para ser almacenadas en RDDs nuevos\n",
    "- Tambi√©n regresan resultados a ambas partes: el *driver* o un almacenamiento externo\n",
    "- Los RDDs son re-calculados por cada acci√≥n que se les ejecuta\n",
    "- Pueden ser almacenados para un uso posterior: `rdd.persist()`\n",
    "\n",
    "### count()\n",
    "\n",
    "Obtiene las instancias en el RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[42] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect()\n",
    "- `collect()` recupera el RDD completo üöí\n",
    "- √ötil para inspeccionar datasets peque√±os de manera local y para unit-testing\n",
    "- **LOS RESULTADOS DEBEN CABER EN LA MEMORIA DEL EQUIPO LOCAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[44] at parallelize at PythonRDD.scala:480"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take(), takeSample(), first(), top(), takeOrdered() \n",
    "\n",
    "- ```take(n)``` regresa los primeros *n* elementos de un RDD\n",
    "- ```take(n)``` puede obtener resultados sezgados. Su uso es adecuado solo para pruebas o debugging\n",
    "- ```takeSample()``` como el nombre lo indica, es el m√°s adecuado para tomar una muesta del dataset\n",
    "- ```first(n)``` al igual que ```take(n)```, obtiene los primeros *n* elementos de un RDD\n",
    "- ```top(), takeOrdered()``` como m√©todos m√°s formales para obtener elementos ordenados de un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([5, 1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 1]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(4, lambda n: -n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce()\n",
    "Toma dos elementos del mismo tipo y regresa un nuevo elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduce(lambda x, y:  x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia\n",
    "- Spark re-calcula los RDDs cada vez que se llama a una acci√≥n:\n",
    "    - Esto puede ser caro y tambi√©n causar un tr√°fico innecesario desde el disco (lectura)\n",
    "- Podemos evitar esto almacenando datos en cach√© con ```persist()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Causa a Spark el recargar la variable \"lineas\" desde el disco üôä\n",
    "lineasPython.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md MapPartitionsRDD[57] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.persist() # Ahora, este RDD se mantiene en RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark no volver√° a hacer el c√≥mputo para \"lineas\" cada vez que es usado\n",
    "lineasPython.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo un Pipeline de operaciones para RDDs\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    ">>> lineas = sc.textFile(\"README.md\")\n",
    ">>> lineas.map(...).filter(...).count(...)\n",
    "\n",
    "\n",
    "\n",
    ">>> lineas = sc.textFile(\"README.md\")\n",
    ">>> (lineas\n",
    "     .map(...)\n",
    "     .filter(...)\n",
    "     .count(...))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineas.filter(lambda line :  \"Python\" in line).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
