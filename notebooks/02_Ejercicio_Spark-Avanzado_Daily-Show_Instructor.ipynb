{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FiveThirtyRight: Every Guest Jon Stewart Ever Had On ‘The Daily Show’](https://fivethirtyeight.com/features/every-guest-jon-stewart-ever-had-on-the-daily-show/)\n",
    "\n",
    "\n",
    "\n",
    "### Daily Show Guests\n",
    "\n",
    "Historia original: [Every Guest Jon Stewart Ever Had On ‘The Daily Show’](http://fivethirtyeight.com/datalab/every-guest-jon-stewart-ever-had-on-the-daily-show/)\n",
    "\n",
    "Header | Definition\n",
    "---|---------\n",
    "`YEAR` | The year the episode aired\n",
    "`GoogleKnowlege_Occupation` | Their occupation or office, according to Google's Knowledge Graph or, if they're not in there, how Stewart introduced them on the program.\n",
    "`Show` | Air date of episode. Not unique, as some shows had more than one guest\n",
    "`Group` | A larger group designation for the occupation. For instance, us senators, us presidents, and former presidents are all under \"politicians\"\n",
    "`Raw_Guest_List` | The person or list of people who appeared on the show, according to Wikipedia. The GoogleKnowlege_Occupation only refers to one of them in a given row. \n",
    "\n",
    "Fuente: Google Knowlege Graph, The Daily Show clip library, Wikipedia.\n",
    "\n",
    "\n",
    "CSV: https://github.com/israelzuniga/dlatam-bigdata-workshop/blob/master/notebooks/data/daily_show_guests.csv\n",
    "\n",
    "### Descargar dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/israelzuniga/dlatam-bigdata-workshop/master/notebooks/data/daily_show_guests.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 1.\n",
    "\n",
    "Crear un contexto de Spark, configurar el nombre \"dailyshow\" y nivel de logging en \"ALL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"dailyshow\")\n",
    "sc.setLogLevel(\"ALL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Context](http://www.dataquest.io/blog/images/misc/cluster-overview.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/latest/cluster-overview.html#components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2.\n",
    "\n",
    "Crear un RDD a partir del archivo CSV e inspeccionar las primeras cinco líneas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = sc.textFile(\"daily_show_guests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. \n",
    "\n",
    "Del RDD anterior, crear un nuevo RDD donde se separen los strings por cada coma (',') de la línea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_show = raw_data.map(lambda line: line.split(',')) # Pipeline\n",
    "daily_show.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines Spark vs Hadoop:\n",
    "\n",
    "![](https://www.codeproject.com/KB/miscctrl/1023037/SparkVsHadoop.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Obtener el número de invitados durante los años del show\n",
    "\n",
    "Queremos obtener un conteo del número de invitados en cada año que el show ha estado al aire. Si daily_show fuera una \"Lista de listas\" en Python, usaríamos el siguiente código para obtener el resultado:\n",
    "\n",
    "```python\n",
    "\n",
    "tally = dict()\n",
    "for line in daily_show:\n",
    "  year = line[0]\n",
    "  if year in tally.keys():\n",
    "    tally[year] = tally[year] + 1\n",
    "  else:\n",
    "    tally[year] = 1\n",
    "```\n",
    "\n",
    "\n",
    "** Cómo lo haríamos en PySpark? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tally = daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tally es un RDD, por lo tanto no podemos usar métodos tradicionales de Python como len()\n",
    "\n",
    "tally.take(tally.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Filtrar el RDD para eliminar la tupla ('YEAR', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_year(line):\n",
    "    if line[0] == 'YEAR':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "filtered_daily_show = daily_show.filter(lambda line: filter_year(line))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#filtered_daily_show.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_daily_show.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Filtrar los actores sin profesión listada,  convertir a minúsculas cada texto, generar el conteo de profesiones y obtener 10 valores\n",
    "\n",
    "#### 6a. En variables separadas \n",
    "#### 6b. En un pipeline; ordenar por valor (ascendente) y retornar los primeros 15 elementos\n",
    "##### Hint: Ordenar con:   ```sortBy(lambda a: -a[1])```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paso1 = filtered_daily_show.filter(lambda line: line[1] != '')\n",
    "paso2 = paso1.map(lambda line: (line[1].lower(), 1))\n",
    "paso3 = paso2.reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "paso3.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
    "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
    "                   .reduceByKey(lambda x,y: x+y) \\\n",
    "                   .sortBy(lambda a: -a[1]) \\\n",
    "                   .take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
